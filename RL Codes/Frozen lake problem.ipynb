{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgTHW1jTc94u",
        "colab_type": "text"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/bcs-iitk/BCS_Workshop_Apr_20/blob/master/Machine_Learning/Assignment/ML.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/bcs-iitk/BCS_Workshop_Apr_20/blob/master/Machine_Learning/Assignment/ML.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Machine_Learning/Assignment/ML.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiU-x0ujcRkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright (c) 2020 Brain and Cognitive Society, IIT Kanpur [ BCS @IITK ]\n",
        "# Copyright under MIT License, must reference https://github.com/bcs-iitk/BCS_Workshop_Apr_20 if used anywhere else.\n",
        "# Author: Shashi Kant (http://shashikg.github.io/)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6GMP27JdNG2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Note: Do not forget to click on **Copy to Drive** in Google Colab to save a copy of this assignment.\n",
        "\n",
        "![copy2drive](https://github.com/bcs-iitk/BCS_Workshop_Apr_20/raw/master/Machine_Learning/Assignment/copy2drive.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WVBfvzCC5TiP"
      },
      "source": [
        "## Reinforcement Learning\n",
        "In this you have to implement and train an RL agent to find a path for a frozen lake problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DBLEA_dS5TiO"
      },
      "source": [
        "### Frozen Lake Problem Description:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MGfQR-6R5TiN"
      },
      "source": [
        "> Imagine there is a frozen lake stretching from your home to your office; you have to walk on the frozen lake to reach your office. But oops! There are holes in the frozen lake so you have to be careful while walking on the frozen lake to avoid getting trapped in the holes. [[src](https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781788836524/3/ch03lvl1sec32/solving-the-frozen-lake-problem)]\n",
        "\n",
        "![frozen-lake](https://static.packt-cdn.com/products/9781788836524/graphics/49f3e058-2f32-40e8-9992-b53d1f57d138.png)\n",
        "\n",
        "\n",
        "Two task you have to do here:\n",
        "\n",
        "*   Implement a frozen lake scenario given the inputs, number of holes (M) and size of the lake (N) (Assume the lake is square). Starting point will be (0, 0) and goal will be to reach at (N-1, N-1)\n",
        "*   Implemenat Q-learning method to learn a path from start to goal.\n",
        "*   Use the following reward scheme: 50 points on reaching the goal, -50 points on stepping on a hole.\n",
        "\n",
        "#### Q-learning\n",
        "Recall from the lecture video that `Q[state, action]` gives you an action state pair to get an optimal policy. Recall the Q-Loss from the lecture video i.e:\n",
        "> $E = ||r + \\gamma \\cdot \\max_{a'} Q(s', a') - Q(s, a)||^2$\n",
        "\n",
        "Use gradient descent to minimise $E$ and work out a learning rule for $Q(s, a)$. \n",
        "> Take $\\max_{a'} Q(s', a')$ and $r$ to be independent of $Q(s, a)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_RdKzEut5TiN"
      },
      "source": [
        "### Defining important functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2JNc2whU5TiI",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oW1vCqkT5TiF",
        "colab": {}
      },
      "source": [
        "ActionMap = ['Up', 'Right', 'Down', 'Left']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f1qyjSO85TiB",
        "colab": {}
      },
      "source": [
        "def get_board(N, M):\n",
        "  # should return an N x N size frozen lake - board with M randomle placed holes.\n",
        "  # use 'S' representation for starting point\n",
        "  # use 'G' representation for goal point\n",
        "  # use 'H' representation for holes\n",
        "  # use 'F' for frozen lakes\n",
        "  # use 'C' for displaying agents current position on the board.\n",
        "  # Refer the representation from the image shown above\n",
        "\n",
        "  # Write your code here ----------\n",
        "  board = np.chararray(N*N)\n",
        "  board[0] = 'S'\n",
        "  board[N*N - 1] = 'G'\n",
        "  for i in range(1,M+1):\n",
        "      board[i] = 'H'\n",
        "  for i in range(M+1,N*N-1):\n",
        "      board[i] = 'F'\n",
        "  np.random.shuffle(board[1:N*N-1])\n",
        "  board = np.reshape(board, (N,N))\n",
        "  # -------------------------------\n",
        "\n",
        "  return board"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aBEuHQy55Th-",
        "colab": {}
      },
      "source": [
        "def get_reward(board, N, M):\n",
        "  # should return an N x N size reward table for the generated frozen lake scenario\n",
        "  # use 50 reward for 'G' point\n",
        "  # use -50 reward for 'H' point\n",
        "  # o for rest.\n",
        "\n",
        "  # Write your code here ----------\n",
        "  rewardd = np.zeros(shape=(N,N))\n",
        "  for i in range(N):\n",
        "      for j in range(N):\n",
        "          if board[i][j]==b'H':\n",
        "              rewardd[i][j] = -50\n",
        "  rewardd[N-1][N-1] = 50\n",
        "  # -------------------------------\n",
        "\n",
        "  return rewardd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YIOTfQtU5Th6",
        "colab": {}
      },
      "source": [
        "class FrozenLake:\n",
        "  def __init__(self, N, M):\n",
        "    # Recall python class, this function is called when you first initialise the class\n",
        "    # Should intialise the board and reward table based on the reward scheme\n",
        "    # Select M numbers of holes randomly\n",
        "\n",
        "    self.board = get_board(N, M)\n",
        "    self.init_board = copy.deepcopy(self.board)\n",
        "    self.reward = get_reward(self.board, N, M)\n",
        "    self.state = (0, 0)\n",
        "    self.finish = 0\n",
        "    self.N = N\n",
        "\n",
        "  def reset(self):\n",
        "    # should reset the env with board to initial state\n",
        "    # hint: set self.state at 0, 0 and use self.init_board to reset self.board\n",
        "\n",
        "    # Write your code here ----------\n",
        "    self.state = (0,0)\n",
        "    self.board = self.init_board\n",
        "    # -------------------------------\n",
        "    self.finish = 0\n",
        "\n",
        "    return self.state\n",
        "  \n",
        "  def step(self, action):\n",
        "    # ===== Action Table =========\n",
        "    #     0 -- UP\n",
        "    #     1 -- RIGHT\n",
        "    #     2 -- DOWN\n",
        "    #     3 -- LEFT\n",
        "    # perform the given action and get update the  self.state, get reward, and update the self.board according to new state\n",
        "    # update the self.board means update the new position with 'C' and replace previous position with {'S', 'F', 'G'} which is actually there according to the self.init_board\n",
        "    # Write your code here ----------\n",
        "    r_reward = 0\n",
        "    if action==0:\n",
        "        if self.state[0] != self.N-1:\n",
        "            \n",
        "            r_reward = self.reward[self.state[0]+1][self.state[1]]\n",
        "            self.board[self.state[0]][self.state[1]] = self.init_board[self.state[0]][self.state[1]]\n",
        "            self.board[self.state[0]+1][self.state[1]] = b'C'\n",
        "            \n",
        "            self.state = (self.state[0]+1,self.state[1])\n",
        "    if action==1:\n",
        "        if self.state[1] != self.N-1:\n",
        "        \n",
        "            r_reward = self.reward[self.state[0]][self.state[1]+1]\n",
        "            self.board[self.state[0]][self.state[1]] = self.init_board[self.state[0]][self.state[1]]\n",
        "            self.board[self.state[0]][self.state[1]+1] = b'C'\n",
        "            \n",
        "            self.state = (self.state[0],self.state[1]+1)\n",
        "    if action==2:\n",
        "        if self.state[0] != 0:\n",
        "            \n",
        "            r_reward = self.reward[self.state[0]-1][self.state[1]]\n",
        "            self.board[self.state[0]][self.state[1]] = self.init_board[self.state[0]][self.state[1]]\n",
        "            self.board[self.state[0]-1][self.state[1]] = b'C'\n",
        "            \n",
        "            self.state = (self.state[0]-1,self.state[1])\n",
        "    if action==3:\n",
        "        if self.state[1] != 0:\n",
        "            \n",
        "            r_reward = self.reward[self.state[0]][self.state[1]-1]\n",
        "            self.board[self.state[0]][self.state[1]] = self.init_board[self.state[0]][self.state[1]]\n",
        "            self.board[self.state[0]][self.state[1]-1] = b'C'\n",
        "            \n",
        "            self.state = (self.state[0],self.state[1]-1)\n",
        "    # -------------------------------\n",
        "    \n",
        "    # status to check if you reached your goal\n",
        "    if self.state == (self.N-1, self.N-1):\n",
        "        self.finish = 1\n",
        "        \n",
        "    return self.state, r_reward, self.finish\n",
        "  \n",
        "  def get_random_action(self):\n",
        "    # ===== Action Table =========\n",
        "    #     0 -- UP\n",
        "    #     1 -- RIGHT\n",
        "    #     2 -- DOWN\n",
        "    #     3 -- LEFT\n",
        "    # should return a possible random action out of the four\n",
        "    # hint: note that when you are around the corner or sides of the board not all four action will be available for you\n",
        "\n",
        "    # Write your code here ----------\n",
        "    no = random.randint(10,99999)\n",
        "    if self.state == (0,0):\n",
        "        action = no%2\n",
        "    elif self.state == (self.N-1,0):\n",
        "        if no%2 == 0:\n",
        "            action = 1\n",
        "        else:\n",
        "            action = 2\n",
        "    elif self.state == (self.N-1,self.N-1):\n",
        "        if no%2 == 0:\n",
        "            action = 2\n",
        "        else:\n",
        "            action = 3\n",
        "    elif self.state == (0,self.N-1):\n",
        "        if no%2 == 0:\n",
        "            action = 0\n",
        "        else:\n",
        "            action = 3\n",
        "    elif self.state[1] == 0:\n",
        "        action = no%3\n",
        "    elif self.state[1] == self.N-1:\n",
        "        if no%3 == 0:\n",
        "            action = 0\n",
        "        if no%3 == 1:\n",
        "            action = 2\n",
        "        else :\n",
        "            action = 3\n",
        "    elif self.state[0] == self.N-1:\n",
        "        if no%3 == 0:\n",
        "            action = 1\n",
        "        if no%3 == 1:\n",
        "            action = 2\n",
        "        else :\n",
        "            action = 3\n",
        "    elif self.state[0] == 0:\n",
        "        if no%3 == 0:\n",
        "            action = 0\n",
        "        if no%3 == 1:\n",
        "            action = 1\n",
        "        else :\n",
        "            action = 3\n",
        "    else:\n",
        "        action = no%4\n",
        "    \n",
        "    return action    \n",
        "      \n",
        "  def display(self):\n",
        "    print(self.init_board)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7trU5rXV5Th5"
      },
      "source": [
        "### Environment creation and learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pifNkUAK5Th0",
        "colab": {}
      },
      "source": [
        "def explore_exploit(env, Q, state, episode):\n",
        "  # Notice that if you always select your new action based on maximum Q-value you will never get to see any new path right?\n",
        "  # You have to explore the environment to know new paths\n",
        "  # Write your code here to randomly select whether you want to explore or exploit\n",
        "  # The probability of exploration should be exp(-episode*5e-4)\n",
        "  # for exploration get some random action\n",
        "  # for exploitation get action based on max Q value\n",
        "\n",
        "  # Write your code here ----------\n",
        "  prob = [0,1]\n",
        "  weights = [1-math.exp(-episode*5e-4),math.exp(-episode*5e-4)]\n",
        "  one_for_exploration = random.choices(prob, weights)\n",
        "  if one_for_exploration == [1]:\n",
        "      action1 = env.get_random_action()\n",
        "  else:\n",
        "      action1 = np.argmax(Q[state[0],state[1],:])\n",
        "\n",
        "  # -------------------------------\n",
        "\n",
        "  return action1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G_BrXZTL5Thw",
        "colab": {}
      },
      "source": [
        "def init_env_and_learn(N=6, M=12, gamma=0.8, lr=0.8):\n",
        "  # gamma: gamma param of total discounted reward\n",
        "  # lr: learning rate for Q updates\n",
        "  # N = grid size of frozen lake wil be N x N\n",
        "  # M = Number of holes\n",
        "  # returns env, Q-function, rewards\n",
        "\n",
        "  env = FrozenLake(N, M)\n",
        "  Q = np.zeros((N, N, 4))\n",
        "\n",
        "  total_episodes = 3000 # i.e. the number of times your RL agent will run through the board.\n",
        "  max_steps = N*N*3 # maximum number of steps to perform\n",
        "\n",
        "  rewards = []\n",
        "  for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    total_rewards = 0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "      action = explore_exploit(env, Q, state, episode)\n",
        "      \n",
        "      # Write your code here ----------------------------------------------------------\n",
        "      # Should perform the action get reward, new_state, finish status and update the Q value\n",
        "\n",
        "      new_state, rewarded, finish = env.step(action)\n",
        "      Q[state[0], state[1], action] = Q[state[0], state[1], action] + lr * (rewarded + gamma * np.max(Q[new_state[0], new_state[1], :]) - Q[state[0], state[1], action])\n",
        "      # -------------------------------------------------------------------------------\n",
        "\n",
        "      total_rewards += rewarded\n",
        "      state = new_state\n",
        "\n",
        "      if finish == 1: \n",
        "          break\n",
        "\n",
        "    rewards.append(total_rewards)\n",
        "\n",
        "  return env, Q, rewards"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Jiex3R-5Ths",
        "colab": {}
      },
      "source": [
        "def travel_path(env, Q, N):\n",
        "  # write a function to display a sequence of path performed using the learned Q-values\n",
        "  # show initial and final frozen lake board \n",
        "  # to perform an action at a state simply take max of Q at that state\n",
        "\n",
        "    #     0 -- UP\n",
        "    #     1 -- RIGHT\n",
        "    #     2 -- DOWN\n",
        "    #     3 -- LEFT\n",
        "\n",
        "  # Write your code here ----------\n",
        "  print(env1.reward)\n",
        "  state = (0,0)\n",
        "  while state != (N-1, N-1):\n",
        "    act = np.argmax(Q[state[0],state[1],:])\n",
        "    print(ActionMap[act])\n",
        "    if act == 0:\n",
        "        new_state = (state[0]+1,state[1])\n",
        "    elif act == 1:\n",
        "        new_state = (state[0],state[1]+1)\n",
        "    elif act == 2:\n",
        "        new_state = (state[0]-1,state[1])\n",
        "    else:\n",
        "        new_state = (state[0],state[1]-1)\n",
        "    state = new_state\n",
        "  # -------------------------------\n",
        "\n",
        "  return    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "noLS62YS5Thq"
      },
      "source": [
        "### Use N = 6, M = 10 and learn the models for following sets of gamma and lr:\n",
        "\n",
        "*   `(gamma, lr) = (0.8, 0.8)`\n",
        "*   `(gamma, lr) = (0.95, 0.8)`\n",
        "*   `(gamma, lr) = (0.6, 0.8)`\n",
        "*   `(gamma, lr) = (0.8, 0.95)`\n",
        "*   `(gamma, lr) = (0.8, 0.1)`\n",
        "\n",
        "Plot rewards vs episode for each of them and compare.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3XF_ena45Thi",
        "colab": {}
      },
      "source": [
        "# Write your code here ----------\n",
        "env2, Q2, rewards2 = init_env_and_learn(N=6, M=10, gamma=0.95, lr=0.8)\n",
        "env3, Q3, rewards3 = init_env_and_learn(N=6, M=10, gamma=0.6, lr=0.8)\n",
        "env4, Q4, rewards4 = init_env_and_learn(N=6, M=10, gamma=0.8, lr=0.95)\n",
        "env5, Q5, rewards5 = init_env_and_learn(N=6, M=10, gamma=0.8, lr=0.1)\n",
        "env1, Q1, rewards1 = init_env_and_learn(N=6, M=10, gamma=0.8, lr=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "99cffa25-2ac4-409d-f988-47ee874e9f37",
        "id": "5CliDa525ThU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "fig, axs = plt.subplots(2, 3)\n",
        "axs[0, 0].plot(rewards1)\n",
        "axs[0, 0].set_title('0.8, 0.8')\n",
        "axs[0, 1].plot(rewards2, 'tab:orange')\n",
        "axs[0, 1].set_title('0.95, 0.8')\n",
        "axs[0, 2].plot(rewards3)\n",
        "axs[0, 2].set_title('0.6, 0.8')\n",
        "axs[1, 0].plot(rewards4, 'tab:green')\n",
        "axs[1, 0].set_title('0.8, 0.95')\n",
        "axs[1, 1].plot(rewards5, 'tab:red')\n",
        "axs[1, 1].set_title('0.8, 0.1')\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='episode', ylabel='reward')\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()\n",
        "\n",
        "plt.show()\n",
        "# # -------------------------------\n",
        "\n",
        "print(\"Gamma = 0.8 and learning rate = 0.8 is giving the best result\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncpwWNkoppRynhY1SSinHaWGjlFLKcf8Pf0RsSDtww3MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LVxJTEMd5ThS"
      },
      "source": [
        "### Use N = 6, M = 10 and learn a models with (gamma, lr) = (0.8, 0.8)\n",
        "After learning the model, display a path traveled from source to goal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7f0103e4-188d-4d25-a1e5-4231cc678d22",
        "id": "J-iOtajD5ThC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Write your code here ----------\n",
        "# print(env.print_board())\n",
        "travel_path(env1,Q1,N=6)\n",
        "# -------------------------------"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0. -50.   0. -50.   0.   0.]\n",
            " [  0.   0.   0.   0. -50. -50.]\n",
            " [  0.   0.   0.   0.   0.   0.]\n",
            " [-50.   0.   0.   0.   0. -50.]\n",
            " [-50.   0.   0. -50.   0.   0.]\n",
            " [  0. -50. -50.   0.   0.  50.]]\n",
            "Up\n",
            "Up\n",
            "Right\n",
            "Up\n",
            "Right\n",
            "Right\n",
            "Right\n",
            "Up\n",
            "Right\n",
            "Up\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OgtEBZg75Tgv",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}